# Project 2 Report

Read the [project 2
specification](https://github.com/feit-comp30019/project-2-specification) for
details on what needs to be covered here. You may modify this template as you see fit, but please
keep the same general structure and headings.

Remember that you must also continue to maintain the Game Design Document (GDD)
in the `GDD.md` file (as discussed in the specification). We've provided a
placeholder for it [here](GDD.md).

## Table of Contents

- [Evaluation Plan](#evaluation-plan)
- [Evaluation Report](#evaluation-report)
- [Shaders and Special Effects](#shaders-and-special-effects)
- [Summary of Contributions](#summary-of-contributions)
- [References and External Resources](#references-and-external-resources)

## Evaluation Plan

### Evaluation techniques: Which evaluation techniques will you use and why? What tasks will you ask participants to perform?

#### Observational Technique:
##### Cooperative Evaluation
+ Analyst and participant evaluate game together
+ Discuss any identified problems and potential solutions together with the participants
##### Questions:
+ How did the atmosphere of the game make you feel throughout your gameplay experience?
+ What aspect of the game stood out to you the most?
+ Was there any moment where you felt confused or uncertain about what to do next? 
+ How did the eerie elements (sfx) affect your exploration of the game environment?
+ How are the controls?
+ What do you like most about our game?
+ What do you think could be improved?
+ What do you think of the difficulty of the game?
+ What do you think the game is lacking in order to achieve a more eerie effect?
+ What part of the game do you think most engaging? What part feels boring?
+ Any moments where atmosphere doesn't feel eerie/unsettling? What contributed to that?
+ What are your thoughts when balancing your sanity bar and crafting light sources in the game? Do you face any challenges?


#### Query Technique:
##### Questionnaires
+ Participants will play the game on WebGL and fill out a survey form
+ The survey form will include a section to rate each aspect of the gameplay
+ The survey form will also include a section to give text feedback for each aspect of the gameplay, as well as the overall game itself
+ Things that we want feedback / ratings on:
+ How does the player feel whilst playing the game?
+ What do they think about the sanity system (does it stress them out?)
+ Does the player feel incentivized to craft light sources?


### Participants: How will you recruit participants? What qualifying criteria will you use to ensure that they are representative of your target audience?

+ Our target audience is teenagers and young adults aged 15 - 28
+ We will recruit participants that belong to the same demographic as our target audience
+ Recruitment method 1: ask university friends and family to volunteer
+ Recruitment method 2: post on social media / online platforms such as Reddit


### Data collection: What sort of data is being collected? How will you collect the data? What tools will you use?

+ Quantitative data
  + Gameplay rating: Game mechanic / Graphic / Theme
  + Satisfaction
+ Qualitative data
  + Feedback: What they like/dislike about / What could be improved

+ Tools: Questionnaire (Survey) for Quantitative data and Qualitative data


### Data analysis: How will you analyse the data? What metrics will you use to evaluate your game, and provide a basis for making changes?

#### For Observational Technique:
+ Affinity Diagram: Analyse main findings by grouping the similar insights
+ For Questionnaire:
  + Analyse summary statistics of quantitative data (i.e. mean, median, stdev)
  + Produce visual graphs of the scores for each aspect of the game to identify which part needs improvement
 
### Timeline: What is your timeline for completing the evaluation? When will you make changes to the game?
<img src="timeline.png" alt="timeline photo" style="height: 100px; width:100px;"/>

# Cooperative Evaluation Protocol for Game Testing

## Overview

This protocol outlines a process for conducting a cooperative evaluation of test players engaging with a game, focusing on collaborative assessment and feedback.

## Objectives

- Observe player interactions.
- Identify issues and gather feedback.
- Discuss potential solutions together.

## Preparation

1. **Select Participants:** 
   - Recruit 3-5 players representing your target audience.

2. **Set Up Environment:** 
   - Ensure a comfortable, distraction-free space with all necessary equipment.

3. **Materials:** 
   - Prepare observation checklists and recording tools (with consent).

## Protocol Steps

1. **Introduction (5 min):**
   - Introduce participants and explain the purpose of the evaluation.

2. **Gameplay Session (15 min):**
   - Allow participants to play while analysts observe and take notes.

3. **Cooperative Discussion (10 min):**
   - Gather for a discussion, encouraging participants to share their experiences.
   - Analysts facilitate conversation about identified issues and potential solutions.

4. **Wrap-Up (5 min):**
   - Summarise findings and thank participants for their input.

## Post-Session

1. **Analyse Notes:**
   - Review notes and recordings, compiling a report on key findings.

2. **Prioritise Issues:**
   - Rank issues based on how often they occur and their impact, discussing with the development team.

3. **Follow-Up:**
   - Share findings with everyone involved and plan future evaluations if necessary.


## Evaluation Report

TODO (due milestone 3) - see specification for details

## Shaders and Special Effects

TODO (due milestone 3) - see specification for details

## Summary of Contributions

TODO (due milestone 3) - see specification for details

## References and External Resources

TODO (to be continuously updated) - see specification for details
